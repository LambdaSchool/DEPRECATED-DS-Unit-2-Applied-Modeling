{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lambda School Data Science — Regression 2_ \n",
    "\n",
    "This sprint, your project is Caterpillar Tube Pricing: Predict the prices suppliers will quote for industrial tube assemblies.\n",
    "\n",
    "# Log-Linear Regression, Feature Engineering|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "- log-transform regression target with right-skewed distribution\n",
    "- use regression metric: RMSLE\n",
    "- do feature engineering with relational data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process\n",
    "\n",
    "** Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning, \"A universal workflow of machine learning\"**\n",
    " \n",
    "> **1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
    "\n",
    "> **2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
    "\n",
    "> **3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
    "\n",
    "> **4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
    "\n",
    "> **5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
    "\n",
    "> **6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
    "\n",
    "> **Iterate on feature engineering: add new features, or remove features that don’t seem to be informative.** Once you’ve developed a satisfactory model configuration, you can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caterpillar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the problem 🚜\n",
    "\n",
    "**[Description](https://www.kaggle.com/c/caterpillar-tube-pricing/overview/description)**\n",
    "\n",
    "> Like snowflakes, it's difficult to find two tubes in Caterpillar's diverse catalogue of machinery that are exactly alike. Tubes can vary across a number of dimensions, including base materials, number of bends, bend radius, bolt patterns, and end types.\n",
    "\n",
    "> Currently, Caterpillar relies on a variety of suppliers to manufacture these tube assemblies, each having their own unique pricing model. This competition provides detailed tube, component, and annual volume datasets, and challenges you to predict the price a supplier will quote for a given tube assembly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the data on which you'll train\n",
    "\n",
    "Data Description\n",
    "\n",
    "    The dataset is comprised of a large number of relational tables that describe the physical properties of tube assemblies. You are challenged to combine the characteristics of each tube assembly with supplier pricing dynamics in order to forecast a quote price for each tube. The quote price is labeled as cost in the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose how you'll measure success on your problem\n",
    "\n",
    "\n",
    "> Which metrics will you monitor on your validation data?\n",
    "\n",
    "**[Evaluation](https://www.kaggle.com/c/caterpillar-tube-pricing/overview/evaluation)**\n",
    "\n",
    "> Submissions are evaluated one the Root Mean Squared Logarithmic Error (RMSLE). The RMSLE is calculated as\n",
    ">\n",
    "> $\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(\\log \\left(p_{i}+1\\right)-\\log \\left(a_{i}+1\\right)\\right)^{2}}$\n",
    ">\n",
    "> Where:\n",
    ">\n",
    "> - $n$ is the number of price quotes in the test set\n",
    "> - $p_i$ is your predicted price\n",
    "> - $a_i$ is the actual price\n",
    "> - $log(x)$ is the natural logarithm\n",
    "\n",
    "**[Scikit-Learn User Guide](https://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-log-error)**\n",
    "\n",
    "> The `mean_squared_log_error` function is best to use when targets have exponential growth, such as population counts, average sales of a commodity over a span of years etc. Note that this metric penalizes an under-predicted estimate greater than an over-predicted estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine your evaluation protocol\n",
    "\n",
    "> Which portion of the data should you use for validation?\n",
    "\n",
    "**Rachel Thomas, [How (and why) to create a good validation set](https://www.fast.ai/2017/11/13/validation-sets/)**\n",
    "\n",
    "> You will want to create your own training and validation sets (by splitting the Kaggle “training” data). You will just use your smaller training set (a subset of Kaggle’s training data) for building your model, and you can evaluate it on your validation set (also a subset of Kaggle’s training data) before you submit to Kaggle.\n",
    "\n",
    "> When is a random subset not good enough?\n",
    "> - Time series\n",
    "> - New people, new boats, new…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "- Start a clean notebook.\n",
    "- Get the [Caterpillar data from Kaggle](https://www.kaggle.com/c/caterpillar-tube-pricing/data).\n",
    "- Do train/validate/test split.\n",
    "- Select features from `train_set.csv`, `tube.csv`, and at least one more file.\n",
    "- Fit a model.\n",
    "- Get your validation RMSLE (or RMSE with log-transformed targets).\n",
    "- [Submit](https://www.kaggle.com/c/caterpillar-tube-pricing/submit) your predictions to the Kaggle competition.\n",
    "- Commit your notebook to your fork of the GitHub repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretch Goals\n",
    "- Improve your scores on Kaggle.\n",
    "- Make visualizations and share on Slack.\n",
    "- Look at [Kaggle Kernels](https://www.kaggle.com/c/caterpillar-tube-pricing/kernels) for ideas about feature engineering and visualization.\n",
    "\n",
    "Read [Better Explained](https://betterexplained.com/) Exponents & Logs series:\n",
    "\n",
    "1. [An Intuitive Guide To Exponential Functions & e](https://betterexplained.com/articles/an-intuitive-guide-to-exponential-functions-e/)\n",
    "2. [Demystifying the Natural Logarithm (ln)](https://betterexplained.com/articles/demystifying-the-natural-logarithm-ln/)\n",
    "3. [A Visual Guide to Simple, Compound and Continuous Interest Rates](https://betterexplained.com/articles/a-visual-guide-to-simple-compound-and-continuous-interest-rates/)\n",
    "4. [Common Definitions of e (Colorized)](https://betterexplained.com/articles/definitions-of-e-colorized/)\n",
    "5. [Understanding Exponents (Why does 0^0 = 1?)](https://betterexplained.com/articles/understanding-exponents-why-does-00-1/)\n",
    "6. [Using Logarithms in the Real World](https://betterexplained.com/articles/using-logs-in-the-real-world/)\n",
    "7. [How To Think With Exponents And Logarithms](https://betterexplained.com/articles/think-with-exponents/)\n",
    "8. [Understanding Discrete vs. Continuous Growth](https://betterexplained.com/articles/understanding-discrete-vs-continuous-growth/)\n",
    "9. [What does an exponent really mean?](https://betterexplained.com/articles/what-does-an-exponent-mean/)\n",
    "10. [Q: Why is e special? (2.718..., not 2, 3.7 or another number?)](https://betterexplained.com/articles/q-why-is-e-special-2-718-not-other-number/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates root mean squared log error.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the [Caterpillar data from Kaggle](https://www.kaggle.com/c/caterpillar-tube-pricing/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1. Kaggle web UI\n",
    " \n",
    "Sign in to Kaggle and go to the [Caterpillar Tube Pricing](https://www.kaggle.com/c/caterpillar-tube-pricing) competition. Go to the Data page. After you have accepted the rules of the competition, use the download buttons to download the data.\n",
    "\n",
    "\n",
    "#### Option 2. Kaggle API\n",
    "\n",
    "1. [Follow these instructions](https://github.com/Kaggle/kaggle-api#api-credentials) to create a Kaggle “API Token” and download your `kaggle.json` file.\n",
    "\n",
    "2. Put `kaggle.json` in the correct location.\n",
    "\n",
    "  - If you're using Anaconda, put the file in the directory specified in the [instructions](https://github.com/Kaggle/kaggle-api#api-credentials).\n",
    "\n",
    "  - If you're using Google Colab, upload the file to your Google Drive, and run this cell:\n",
    "\n",
    "  ```\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  %env KAGGLE_CONFIG_DIR=/content/drive/My Drive/\n",
    "  ```\n",
    "\n",
    "3. Install the Kaggle API package.\n",
    "```\n",
    "pip install kaggle\n",
    "```\n",
    "\n",
    "4. After you have accepted the rules of the competiton, use the Kaggle API package to get the data.\n",
    "```\n",
    "kaggle competitions download -c caterpillar-tube-pricing\n",
    "```\n",
    "\n",
    "#### Option 3. GitHub Repo\n",
    "\n",
    "Get the zip file from the [GitHub repo](https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling/tree/master/data/caterpillar), by cloning locally, or downloading directly from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ('https://raw.githubusercontent.com/LambdaSchool/'\n",
    "          'DS-Unit-2-Applied-Modeling/master/data/caterpillar/'\n",
    "          'caterpillar-tube-pricing.zip')\n",
    "filename = 'caterpillar-tube-pricing.zip'\n",
    "\n",
    "file = requests.get(url)\n",
    "open(filename, 'wb').write(file.content)\n",
    "\n",
    "with ZipFile(filename, 'r') as zip:\n",
    "    zip.extractall()\n",
    "    \n",
    "with ZipFile('data.zip', 'r') as zip:\n",
    "    zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "competition_data\\bill_of_materials.csv (21198, 17)\n",
      "competition_data\\components.csv (2048, 3)\n",
      "competition_data\\comp_adaptor.csv (25, 20)\n",
      "competition_data\\comp_boss.csv (147, 15)\n",
      "competition_data\\comp_elbow.csv (178, 16)\n",
      "competition_data\\comp_float.csv (16, 7)\n",
      "competition_data\\comp_hfl.csv (6, 9)\n",
      "competition_data\\comp_nut.csv (65, 11)\n",
      "competition_data\\comp_other.csv (1001, 3)\n",
      "competition_data\\comp_sleeve.csv (50, 10)\n",
      "competition_data\\comp_straight.csv (361, 12)\n",
      "competition_data\\comp_tee.csv (4, 14)\n",
      "competition_data\\comp_threaded.csv (194, 32)\n",
      "competition_data\\specs.csv (21198, 11)\n",
      "competition_data\\test_set.csv (30235, 8)\n",
      "competition_data\\train_set.csv (30213, 8)\n",
      "competition_data\\tube.csv (21198, 16)\n",
      "competition_data\\tube_end_form.csv (27, 2)\n",
      "competition_data\\type_component.csv (29, 2)\n",
      "competition_data\\type_connection.csv (14, 2)\n",
      "competition_data\\type_end_form.csv (8, 2)\n"
     ]
    }
   ],
   "source": [
    "for path in glob('competition_data/*.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    print(path, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do train/validate/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval = pd.read_csv('competition_data/train_set.csv')\n",
    "test = pd.read_csv('competition_data/test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_tube_assemblies = trainval['tube_assembly_id'].unique()\n",
    "train_tube_assemblies, val_tube_assemblies = train_test_split(\n",
    "    trainval_tube_assemblies, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6641, 2214)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tube_assemblies), len(val_tube_assemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_tube_assemblies) & set(val_tube_assemblies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22697, 8), (7516, 8), (30213, 8))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = trainval[trainval['tube_assembly_id'].isin(train_tube_assemblies)]\n",
    "val = trainval[trainval['tube_assembly_id'].isin(val_tube_assemblies)]\n",
    "\n",
    "train.shape, val.shape, trainval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train) + len(val) == len(trainval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin with baselines for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSLE, Mean Baseline: 0.9488613837731072\n",
      "Validation RMSLE, Mean Baseline: 0.934117896930467\n"
     ]
    }
   ],
   "source": [
    "target = 'cost'\n",
    "y_train = train[target]\n",
    "y_val = val[target]\n",
    "\n",
    "y_train_pred = np.full_like(y_train, fill_value=y_train.mean())\n",
    "y_pred = np.full_like(y_val, fill_value=y_train.mean())\n",
    "\n",
    "print('Training RMSLE, Mean Baseline:', rmsle(y_train, y_train_pred))\n",
    "print('Validation RMSLE, Mean Baseline:', rmsle(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2, Mean Baseline: 0.0\n",
      "Validation R^2, Mean Baseline: -7.76664143693484e-05\n"
     ]
    }
   ],
   "source": [
    "print('Training R^2, Mean Baseline:', r2_score(y_train, y_train_pred))\n",
    "print('Validation R^2, Mean Baseline:', r2_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop a first model that does better than a basic baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Random Forest with 1 feature: quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['quantity']\n",
    "X_train = train[features]\n",
    "X_val = val[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 0.11239845565295126\n",
      "Validation R^2 0.1004097364165959\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "r2_train = model.score(X_train, y_train)\n",
    "r2_val = model.score(X_val, y_val)\n",
    "print('Training R^2', r2_train)\n",
    "print('Validation R^2', r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSLE, Random Forest with ['quantity']\n",
      "0.6853727216426102\n",
      "Validation RMSLE, Random Forest with ['quantity']\n",
      "0.6858160465545607\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "print(f'Training RMSLE, Random Forest with {features}')\n",
    "print(rmsle(y_train, y_train_pred))\n",
    "\n",
    "print(f'Validation RMSLE, Random Forest with {features}')\n",
    "print(rmsle(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Select features from `train_set.csv`, `tube.csv`, and at least one more file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your validation RMSLE (or RMSE with log-transformed targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Submit](https://www.kaggle.com/c/caterpillar-tube-pricing/submit) your predictions to the Kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
