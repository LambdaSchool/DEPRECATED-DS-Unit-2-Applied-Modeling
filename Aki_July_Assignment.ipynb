{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aki July Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkiBae4891/DS-Unit-2-Applied-Modeling/blob/master/Aki_July_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_56RQz5RsIqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assignment \n",
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
        "\n",
        "def wrangle(X):\n",
        "    X = X.copy()\n",
        "    \n",
        "    # Engineer date features\n",
        "    X['quote_date'] = pd.to_datetime(X['quote_date'], infer_datetime_format=True)\n",
        "    X['quote_date_year'] = X['quote_date'].dt.year\n",
        "    X['quote_date_month'] = X['quote_date'].dt.month\n",
        "    X = X.drop(columns='quote_date')\n",
        "    \n",
        "    # Merge tube data\n",
        "    tube = pd.read_csv(SOURCE + 'tube.csv')\n",
        "    X = X.merge(tube, how='left')\n",
        "    \n",
        "    # Engineer features from bill_of_materials\n",
        "    materials = pd.read_csv(SOURCE + 'bill_of_materials.csv')\n",
        "    \n",
        "    materials['components_total'] = (materials['quantity_1'].fillna(0) + \n",
        "                                     materials['quantity_2'].fillna(0) + \n",
        "                                     materials['quantity_3'].fillna(0) + \n",
        "                                     materials['quantity_4'].fillna(0) + \n",
        "                                     materials['quantity_5'].fillna(0) + \n",
        "                                     materials['quantity_6'].fillna(0) + \n",
        "                                     materials['quantity_7'].fillna(0) + \n",
        "                                     materials['quantity_8'].fillna(0))\n",
        "\n",
        "    materials['components_distinct'] = (materials['component_id_1'].notnull().astype(int) + \n",
        "                                        materials['component_id_2'].notnull().astype(int) + \n",
        "                                        materials['component_id_3'].notnull().astype(int) + \n",
        "                                        materials['component_id_4'].notnull().astype(int) + \n",
        "                                        materials['component_id_5'].notnull().astype(int) + \n",
        "                                        materials['component_id_6'].notnull().astype(int) + \n",
        "                                        materials['component_id_7'].notnull().astype(int) + \n",
        "                                        materials['component_id_8'].notnull().astype(int))\n",
        "    \n",
        "    # Merge selected features from bill_of_materials\n",
        "    # Just use the first component_id, ignore the others for now!\n",
        "    features = ['tube_assembly_id', 'component_id_1', 'components_total', 'components_distinct']\n",
        "    X = X.merge(materials[features], how='left')\n",
        "    \n",
        "    # Get component_type_id (has lower cardinality than component_id)\n",
        "    components = pd.read_csv(SOURCE + 'components.csv')\n",
        "    components = components.rename(columns={'component_id': 'component_id_1'})\n",
        "    features = ['component_id_1', 'component_type_id']\n",
        "    X = X.merge(components[features], how='left')\n",
        "    \n",
        "    # Count the number of specs for the tube assembly\n",
        "    specs = pd.read_csv(SOURCE + 'specs.csv')\n",
        "    specs['specs_total'] = specs.drop(columns=['tube_assembly_id']).count(axis=1)\n",
        "    features = ['tube_assembly_id', 'specs_total', 'spec1']\n",
        "    X = X.merge(specs[features], how='left')\n",
        "    \n",
        "    # Drop tube_assembly_id because our goal is to predict unknown assemblies\n",
        "    X = X.drop(columns='tube_assembly_id')\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "# Read data\n",
        "trainval = pd.read_csv(SOURCE + 'train_set.csv')\n",
        "test = pd.read_csv(SOURCE + 'test_set.csv')\n",
        "\n",
        "# Split into train & validation sets\n",
        "# All rows for a given tube_assembly_id should go in either train or validation\n",
        "trainval_tube_assemblies = trainval['tube_assembly_id'].unique()\n",
        "train_tube_assemblies, val_tube_assemblies = train_test_split(\n",
        "    trainval_tube_assemblies, random_state=42)\n",
        "train = trainval[trainval.tube_assembly_id.isin(train_tube_assemblies)]\n",
        "val = trainval[trainval.tube_assembly_id.isin(val_tube_assemblies)]\n",
        "\n",
        "# Wrangle train, validation, and test sets\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)\n",
        "\n",
        "# Arrange X matrix and y vector (log-transformed)\n",
        "target = 'cost'\n",
        "X_train = train.drop(columns=target)\n",
        "X_val = val.drop(columns=target)\n",
        "X_test = test.drop(columns='id')\n",
        "y_train = train[target]\n",
        "y_val = val[target]\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_val_log = np.log1p(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW46BN-yAdaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit\n",
        "pipeline.fit(X_train, y_train_log)\n",
        "\n",
        "# Validate\n",
        "y_pred_log = pipeline.predict(X_val)\n",
        "print('Validation Error', rmse(y_val_log, y_pred_log))\n",
        "\n",
        "# Predict\n",
        "def generate_submission(estimator, X_test, filename):\n",
        "    y_pred_log = estimator.predict(X_test)\n",
        "    y_pred = np.expm1(y_pred_log)  # Convert from log-dollars to dollars\n",
        "    submission = pd.read_csv(SOURCE + '../sample_submission.csv')\n",
        "    submission['cost'] = y_pred\n",
        "    submission.to_csv(filename, index=False)\n",
        "    \n",
        "generate_submission(pipeline, X_test, 'submission-02.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dj6JBWSAk7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "rf = pipeline.named_steps['randomforestregressor']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "importances.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}