{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REFERENCE_DS5_gradient_boosting_more_feature_engineering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElisabethShah/DS-Unit-2-Applied-Modeling/blob/master/module2-gradient-boosting/gradient_boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mLjlSwVGRli8"
      },
      "source": [
        "_Lambda School Data Science â€” Applied Modeling_ \n",
        "\n",
        "This sprint, your project is Caterpillar Tube Pricing: Predict the prices suppliers will quote for industrial tube assemblies.\n",
        "\n",
        "# Gradient Boosting\n",
        "\n",
        "\n",
        "#### Objectives\n",
        "- Do feature engineering with relational data\n",
        "- Use xgboost for gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lxo6A73ERli-"
      },
      "source": [
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) â€” slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) â€”Â can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) â€”Â can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) â€”Â can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S3mx5xMnRli_"
      },
      "source": [
        "### Get data\n",
        "\n",
        "\n",
        "#### Option 1. Kaggle web UI\n",
        " \n",
        "Sign in to Kaggle and go to the [Caterpillar Tube Pricing](https://www.kaggle.com/c/caterpillar-tube-pricing) competition. Go to the Data page. After you have accepted the rules of the competition, use the download buttons to download the data.\n",
        "\n",
        "\n",
        "#### Option 2. Kaggle API\n",
        "\n",
        "Follow these [instructions](https://github.com/Kaggle/kaggle-api).\n",
        "\n",
        "#### Option 3. GitHub Repo â€” LOCAL\n",
        "\n",
        "If you are working locally:\n",
        "\n",
        "1. Clone the [GitHub repo](https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling/tree/master/data/caterpillar) locally. The data is in the repo, so you don't need to download it separately.\n",
        "\n",
        "2. Unzip the file `caterpillar-tube-pricing.zip` which is in the data folder of your local repo.\n",
        "\n",
        "3. Unzip the file `data.zip`. \n",
        "\n",
        "4. Run the cell below to assign a constant named `SOURCE`, a string that points to the location of the data on your local machine. The rest of the code in the notebook will use this constant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4llRWHx4EI2q",
        "colab": {}
      },
      "source": [
        "SOURCE = '../data/caterpillar/caterpillar-tube-pricing/competition_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vvyyeP90FB65"
      },
      "source": [
        "#### Option 4. GitHub Repo â€” COLAB\n",
        "\n",
        "If you are working on Google Colab, uncomment and run these cells, to download the data, unzip it, and assign a constant that points to the location of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vzVWh6oGFZJb",
        "outputId": "445fc157-de2d-46d4-edd3-131f01e44b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/caterpillar/caterpillar-tube-pricing.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-09 02:12:35--  https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/caterpillar/caterpillar-tube-pricing.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 823789 (804K) [application/zip]\n",
            "Saving to: â€˜caterpillar-tube-pricing.zipâ€™\n",
            "\n",
            "\r          caterpill   0%[                    ]       0  --.-KB/s               \rcaterpillar-tube-pr 100%[===================>] 804.48K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-08-09 02:12:35 (17.8 MB/s) - â€˜caterpillar-tube-pricing.zipâ€™ saved [823789/823789]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1QG9BiopRljC",
        "outputId": "16624e2d-0029-4dc9-8a97-db6f1933bcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "!unzip caterpillar-tube-pricing.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  caterpillar-tube-pricing.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: sample_submission.csv   \n",
            "replace data.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data.zip                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67Pz81FKRljE",
        "outputId": "ee08bda7-5402-4aaf-863f-8a581d78c7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "   creating: competition_data/\n",
            "  inflating: competition_data/bill_of_materials.csv  \n",
            "  inflating: competition_data/comp_adaptor.csv  \n",
            "  inflating: competition_data/comp_boss.csv  \n",
            "  inflating: competition_data/comp_elbow.csv  \n",
            "  inflating: competition_data/comp_float.csv  \n",
            "  inflating: competition_data/comp_hfl.csv  \n",
            "  inflating: competition_data/comp_nut.csv  \n",
            "  inflating: competition_data/comp_other.csv  \n",
            "  inflating: competition_data/comp_sleeve.csv  \n",
            "  inflating: competition_data/comp_straight.csv  \n",
            "  inflating: competition_data/comp_tee.csv  \n",
            "  inflating: competition_data/comp_threaded.csv  \n",
            "  inflating: competition_data/components.csv  \n",
            "  inflating: competition_data/specs.csv  \n",
            "  inflating: competition_data/test_set.csv  \n",
            "  inflating: competition_data/train_set.csv  \n",
            "  inflating: competition_data/tube.csv  \n",
            "  inflating: competition_data/tube_end_form.csv  \n",
            "  inflating: competition_data/type_component.csv  \n",
            "  inflating: competition_data/type_connection.csv  \n",
            "  inflating: competition_data/type_end_form.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mF8uDQ5wFSny",
        "colab": {}
      },
      "source": [
        "SOURCE = 'competition_data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6_ZDsGjVRljF"
      },
      "source": [
        "## Do feature engineering with relational data\n",
        "\n",
        "Here are some questions â€”Â not answers!\n",
        "\n",
        "### `bill_of_materials`\n",
        "\n",
        "is formatted like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "opLig3sDRljG",
        "outputId": "5d30c6a2-2267-4023-ba93-475281ffe0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "import pandas as pd\n",
        "materials = pd.read_csv(SOURCE + 'bill_of_materials.csv')\n",
        "materials.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tube_assembly_id</th>\n",
              "      <th>component_id_1</th>\n",
              "      <th>quantity_1</th>\n",
              "      <th>component_id_2</th>\n",
              "      <th>quantity_2</th>\n",
              "      <th>component_id_3</th>\n",
              "      <th>quantity_3</th>\n",
              "      <th>component_id_4</th>\n",
              "      <th>quantity_4</th>\n",
              "      <th>component_id_5</th>\n",
              "      <th>quantity_5</th>\n",
              "      <th>component_id_6</th>\n",
              "      <th>quantity_6</th>\n",
              "      <th>component_id_7</th>\n",
              "      <th>quantity_7</th>\n",
              "      <th>component_id_8</th>\n",
              "      <th>quantity_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TA-00001</td>\n",
              "      <td>C-1622</td>\n",
              "      <td>2.0</td>\n",
              "      <td>C-1629</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TA-00002</td>\n",
              "      <td>C-1312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TA-00003</td>\n",
              "      <td>C-1312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TA-00004</td>\n",
              "      <td>C-1312</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TA-00005</td>\n",
              "      <td>C-1624</td>\n",
              "      <td>1.0</td>\n",
              "      <td>C-1631</td>\n",
              "      <td>1.0</td>\n",
              "      <td>C-1641</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  tube_assembly_id component_id_1  ...  component_id_8 quantity_8\n",
              "0         TA-00001         C-1622  ...             NaN        NaN\n",
              "1         TA-00002         C-1312  ...             NaN        NaN\n",
              "2         TA-00003         C-1312  ...             NaN        NaN\n",
              "3         TA-00004         C-1312  ...             NaN        NaN\n",
              "4         TA-00005         C-1624  ...             NaN        NaN\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7_nd_BN1RljI"
      },
      "source": [
        "#### Would this be a better representation?\n",
        "\n",
        "Could pandas melt, crosstab, and other functions help reshape the data like this?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DKgBu-T2RljI"
      },
      "source": [
        "| Crosstab | C-1622 | C-1629 | C-1312 | C-1624 | C-1631 | C-1641 | Distinct | Total |\n",
        "|:--------:|:------:|--------|--------|--------|--------|--------|----------|-------|\n",
        "| TA-00001 | 2      | 2      | 0      | 0      | 0      | 0      | 2        | 4     |\n",
        "| TA-00002 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
        "| TA-00003 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
        "| TA-00004 | 0      | 0      | 2      | 0      | 0      | 0      | 1        | 2     |\n",
        "| TA-00005 | 0      | 0      | 0      | 1      | 1      | 1      | 3        | 3     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fBGv8CIRljJ"
      },
      "source": [
        "### `components`\n",
        "\n",
        "Contains three representations of each component, in order of decreasing cardinality / granularity:\n",
        "\n",
        "- `component_id`\n",
        "- `name`\n",
        "- `component_type_id`\n",
        "\n",
        "What are the pros & cons of these different representations?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gkj_leYyRljJ",
        "colab": {}
      },
      "source": [
        "components = pd.read_csv(SOURCE + 'components.csv')\n",
        "components.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cNowF5PvV1wH",
        "colab": {}
      },
      "source": [
        "components.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZGzxHS-yId5U"
      },
      "source": [
        "### Tip/trick: Want to read all the files at once?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QuektlLMY-hu",
        "colab": {}
      },
      "source": [
        "from glob import glob\n",
        "\n",
        "data = {}\n",
        "for path in glob(SOURCE + '*.csv'):\n",
        "    df = pd.read_csv(path)\n",
        "    filename = path.split('/')[-1]\n",
        "    name = filename.split('.')[0]\n",
        "    data[name] = df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NspIenHYRljL"
      },
      "source": [
        "## Example solution for last assignment ðŸšœ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nxhNfQLlRljL",
        "colab": {}
      },
      "source": [
        "# !pip install category_encoders"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sJB9x5GcRljN",
        "colab": {}
      },
      "source": [
        "import category_encoders as ce\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def rmsle(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
        "\n",
        "def wrangle(X):\n",
        "    X = X.copy()\n",
        "    \n",
        "    # Engineer date features\n",
        "    X['quote_date'] = pd.to_datetime(X['quote_date'], infer_datetime_format=True)\n",
        "    X['quote_date_year'] = X['quote_date'].dt.year\n",
        "    X['quote_date_month'] = X['quote_date'].dt.month\n",
        "    X = X.drop(columns='quote_date')\n",
        "    \n",
        "    # Merge tube data\n",
        "    tube = pd.read_csv(SOURCE + 'tube.csv')\n",
        "    X = X.merge(tube, how='left')\n",
        "    \n",
        "    # Engineer features from bill_of_materials\n",
        "    materials = pd.read_csv(SOURCE + 'bill_of_materials.csv')\n",
        "    \n",
        "    materials['components_total'] = (materials['quantity_1'].fillna(0) + \n",
        "                                     materials['quantity_2'].fillna(0) + \n",
        "                                     materials['quantity_3'].fillna(0) + \n",
        "                                     materials['quantity_4'].fillna(0) + \n",
        "                                     materials['quantity_5'].fillna(0) + \n",
        "                                     materials['quantity_6'].fillna(0) + \n",
        "                                     materials['quantity_7'].fillna(0) + \n",
        "                                     materials['quantity_8'].fillna(0))\n",
        "\n",
        "    materials['components_distinct'] = (materials['component_id_1'].notnull().astype(int) + \n",
        "                                        materials['component_id_2'].notnull().astype(int) + \n",
        "                                        materials['component_id_3'].notnull().astype(int) + \n",
        "                                        materials['component_id_4'].notnull().astype(int) + \n",
        "                                        materials['component_id_5'].notnull().astype(int) + \n",
        "                                        materials['component_id_6'].notnull().astype(int) + \n",
        "                                        materials['component_id_7'].notnull().astype(int) + \n",
        "                                        materials['component_id_8'].notnull().astype(int))\n",
        "    \n",
        "    # Merge selected features from bill_of_materials\n",
        "    # Just use the first component_id, ignore the others for now!\n",
        "    features = ['tube_assembly_id', 'component_id_1', 'components_total', 'components_distinct']\n",
        "    X = X.merge(materials[features], how='left')\n",
        "    \n",
        "    # Get component_type_id (has lower cardinality than component_id)\n",
        "    components = pd.read_csv(SOURCE + 'components.csv')\n",
        "    components = components.rename(columns={'component_id': 'component_id_1'})\n",
        "    features = ['component_id_1', 'component_type_id']\n",
        "    X = X.merge(components[features], how='left')\n",
        "    \n",
        "    # Count the number of specs for the tube assembly\n",
        "    specs = pd.read_csv(SOURCE + 'specs.csv')\n",
        "    specs['specs_total'] = specs.drop(columns=['tube_assembly_id']).count(axis=1)\n",
        "    features = ['tube_assembly_id', 'specs_total', 'spec1']\n",
        "    X = X.merge(specs[features], how='left')\n",
        "    \n",
        "    # Drop tube_assembly_id because our goal is to predict unknown assemblies\n",
        "    X = X.drop(columns='tube_assembly_id')\n",
        "    \n",
        "    return X\n",
        "\n",
        "\n",
        "# Read data\n",
        "trainval = pd.read_csv(SOURCE + 'train_set.csv')\n",
        "test = pd.read_csv(SOURCE + 'test_set.csv')\n",
        "\n",
        "# Split into train & validation sets\n",
        "# All rows for a given tube_assembly_id should go in either train or validation\n",
        "trainval_tube_assemblies = trainval['tube_assembly_id'].unique()\n",
        "train_tube_assemblies, val_tube_assemblies = train_test_split(\n",
        "    trainval_tube_assemblies, random_state=42)\n",
        "train = trainval[trainval.tube_assembly_id.isin(train_tube_assemblies)]\n",
        "val = trainval[trainval.tube_assembly_id.isin(val_tube_assemblies)]\n",
        "\n",
        "# Wrangle train, validation, and test sets\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)\n",
        "\n",
        "# Arrange X matrix and y vector (log-transformed)\n",
        "target = 'cost'\n",
        "X_train = train.drop(columns=target)\n",
        "X_val = val.drop(columns=target)\n",
        "X_test = test.drop(columns='id')\n",
        "y_train = train[target]\n",
        "y_val = val[target]\n",
        "y_train_log = np.log1p(y_train)\n",
        "y_val_log = np.log1p(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vit53URnH6u4",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Make pipeline\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit\n",
        "pipeline.fit(X_train, y_train_log)\n",
        "\n",
        "# Validate\n",
        "y_pred_log = pipeline.predict(X_val)\n",
        "print('Validation Error', rmse(y_val_log, y_pred_log))\n",
        "\n",
        "# Predict\n",
        "def generate_submission(estimator, X_test, filename):\n",
        "    y_pred_log = estimator.predict(X_test)\n",
        "    y_pred = np.expm1(y_pred_log)  # Convert from log-dollars to dollars\n",
        "    submission = pd.read_csv(SOURCE + '../sample_submission.csv')\n",
        "    submission['cost'] = y_pred\n",
        "    submission.to_csv(filename, index=False)\n",
        "    \n",
        "generate_submission(pipeline, X_test, 'submission-02.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OPnPE-xTRljP",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "rf = pipeline.named_steps['randomforestregressor']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "importances.sort_values().plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kKZh950URljR"
      },
      "source": [
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ruupQ-TWjK6D",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QnpC0mHzRljS"
      },
      "source": [
        "#### Jason Brownlee, [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qb_R5_8eRljT",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uu50KGLSqDK0"
      },
      "source": [
        "#### Kaggle RMSLE: 0.29454"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OCKIuAU2RljU"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        "\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        "\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        "\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fË† in areas where it does not perform well.**\n",
        "\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kXCr2NY5RljV"
      },
      "source": [
        "# Assignment\n",
        "- Continue to participate in the [Kaggle Caterpillar competition](https://www.kaggle.com/c/caterpillar-tube-pricing).\n",
        "- Do more feature engineering. \n",
        "- Use xgboost for gradient boosting.\n",
        "- Submit new predictions.\n",
        "- Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "## Stretch Goals\n",
        "- Improve your scores on Kaggle.\n",
        "- Make visualizations and share on Slack.\n",
        "- Look at [Kaggle Kernels](https://www.kaggle.com/c/caterpillar-tube-pricing/kernels) for ideas about feature engineerng and visualization.\n",
        "- Look at the bonus notebook in the repo, about Monotonic Constraints with Gradient Boosting.\n",
        "- Read more about gradient boosting:\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - [A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - [Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (3 minute video)"
      ]
    }
  ]
}